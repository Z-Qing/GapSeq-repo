import pandas as pd
from scipy.ndimage import shift as scipy_shift
import os
import numpy as np
from picasso.gausslq import locs_from_fits_gpufit, initial_parameters_gpufit
from pygpufit import gpufit as gf
from picasso.io import load_movie, save_locs
from picasso.localize import identify_async, identifications_from_futures, get_spots
from picasso.postprocess import link
from picasso.aim import aim
from multiprocessing import Pool
from pystackreg import StackReg
import re
#from scipy.ndimage import affine_transform


class movie_class():
    def __init__(self, movie, info, frame_range=None, roi=None, baseline=None, sensivity=None, gain=None, qe=None):
        if roi is not None:
            movie = movie[:, roi[0]:roi[1], roi[2]:roi[3]]
            info[0]['Height'] = roi[1] - roi[0]
            info[0]['Width'] = roi[3] - roi[2]

        if frame_range is not None:
            movie = movie[frame_range[0]:frame_range[1], :, :]
            info[0]['Frames'] = frame_range[1] - frame_range[0]

        if len(movie.shape) == 2:
            movie = movie[np.newaxis, :, :]

        self.movie = movie

        self.info = info
        self.shape = self.movie.shape
        self.camera_info = {}
        self.camera_info['Baseline'] = 400 if baseline is None else baseline
        self.camera_info['Sensitivity'] = 2.5 if sensivity is None else sensivity
        self.camera_info['Gain'] = 1 if gain is None else gain
        self.camera_info['qe'] = 0.82 if qe is None else qe


    def __getitem__(self, index):
        return self.movie[index]

    def fit_spots_gpufit(self, spots):
        size = spots.shape[1]
        initial_parameters = initial_parameters_gpufit(spots, size)
        spots.shape = (len(spots), (size * size))
        model_id = gf.ModelID.GAUSS_2D_ELLIPTIC

        parameters, states, chi_squares, number_iterations, exec_time = gf.fit(
            spots,
            None,
            model_id,
            initial_parameters,
            tolerance=1e-2,
            max_number_iterations=20,
        )

        parameters[:, 0] *= 2.0 * np.pi * parameters[:, 3] * parameters[:, 4]

        return parameters


    def lq_gpu_fitting(self, min_net_gradient, box):
        current, futures = identify_async(self.movie, min_net_gradient, box, None)
        ids = identifications_from_futures(futures)

        spots = get_spots(self.movie, ids, box, self.camera_info)
        theta = self.fit_spots_gpufit(spots)
        em = self.camera_info["Gain"] > 1
        locs = locs_from_fits_gpufit(ids, theta, box, em)

        localize_info = {
            "Generated by": "Picasso Localize",
            "ROI": None,
            "Box Size": box,
            "Min. Net Gradient": min_net_gradient,
            "Convergence Criterion": 0,
            "Max. Iterations": 0,
            "Pixelsize": 117,
            "Fit method": 'lq-gpu'}

        self.info.append(localize_info)

        return locs

    def correct_frame(idx, frame, drift):
        aim_shift = (-drift[1], -drift[0])
        return idx, scipy_shift(frame, aim_shift, mode='constant', cval=0, order=0)


    def drift_correction(self, min_net_gradient, box, return_movie=False):
        movie = self.movie
        locs = self.lq_gpu_fitting(min_net_gradient, box)
        corrected_locs, new_info, drift = aim(locs, self.info, segmentation=100, intersect_d=20 / 117, roi_r=60 / 117)

        drift = drift.view(np.recarray)


        if return_movie:
            args = [(i, movie[i, :, :], drift[i]) for i in range(movie.shape[0])]
            corrected_movie = np.zeros_like(movie)
            corrected_movie[0, :, :] = movie[0, :, :]
            with Pool() as pool:
                for i, corrected_frame in pool.starmap(self.correct_frame, args):
                    corrected_movie[i, :, :] = corrected_frame

            return corrected_locs, corrected_movie

        else:
            return corrected_locs


    def link_locs(self, min_net_gradient, box, r_max, max_dark_time):
        locs = self.drift_correction(min_net_gradient, box, return_movie=False)
        linked_locs = link(locs, self.info, r_max, max_dark_time)
        return linked_locs



def get_corrected_localizations(nuc_movie_path_list, locs_movie_path, pattern, save):
    # --------------------- get drift corrected and linked locs from nuc movie ---------------------
    nuc_locs = {}
    nuc_firstFrame= {}
    nuc_info = {}
    for f in nuc_movie_path_list:
        nuc_movie, info = load_movie(f)

        height, width = nuc_movie.shape[1], nuc_movie.shape[2]
        nuc_movie_class = movie_class(nuc_movie, info, roi=[0, height, width//2, width])  # get the red channel
        #print(nuc_movie_class.shape)
        # this link function will do the localization fitting and drift correction first
        linked_locs = nuc_movie_class.link_locs(1000, 5, 1, 1)
        #print('done linking')
        # do filtering based on the consideration that one binding will last at least 5 frames
        filtered_locs = linked_locs[linked_locs.len > 5]

        n = re.search(pattern, os.path.basename(f)).group(1)
        nuc_firstFrame[n] = nuc_movie_class[0, :, :]
        nuc_locs[n] = filtered_locs
        nuc_info[n] = nuc_movie_class.info



   # --------------------- align locs to localization movie ---------------------
    ref, info = load_movie(locs_movie_path)
    height, width = ref.shape[1], ref.shape[2]
    ref_first_frame = ref[0, :, :width//2].copy()

    ref_movie_class = movie_class(ref, info, roi=[0, height, 0, width//2], frame_range=(0, 1))
    ref_locs = ref_movie_class.lq_gpu_fitting(500, 5)
    if save:
        save_locs(os.path.dirname(locs_movie_path) + '/ref_locs.hdf5', ref_locs, ref_movie_class.info)

    # align locs from nuc to localization movie
    file_corrected_locs = []
    sr = StackReg(StackReg.RIGID_BODY)
    for nuc in nuc_locs.keys():
        mov = nuc_firstFrame[nuc]
        transform_mat = sr.register(ref_first_frame, mov)
        #print(transform_mat)

        locs = nuc_locs[nuc]
        pos = np.column_stack((locs.x, locs.y))
        aligned_pos = np.dot(pos, transform_mat[:2, :2].T) + transform_mat[:2, 2]
        #print(aligned_pos)
        locs.x = aligned_pos[:, 0]
        locs.y = aligned_pos[:, 1]

        if save:
            save_locs(os.path.dirname(locs_movie_path) + '/{}_locs.hdf5'.format(nuc), locs, nuc_info[nuc])

        locs = pd.DataFrame.from_records(locs)
        locs['nuc'] = nuc
        file_corrected_locs.append(locs)

    file_corrected_locs = pd.concat(file_corrected_locs)

    return file_corrected_locs, pd.DataFrame.from_records(ref_locs)


def outlier_detection(param):
    param = param[['num', 'len', 'photons']].to_numpy()
    total_activity = np.sum(param, axis=0)
    scores = (total_activity - param) / total_activity
    scores = scores.sum(axis=1)

    temperature = 1.0
    exp_scores = np.exp(scores / temperature)

    softmax = exp_scores / np.sum(exp_scores)

    outlier_index = np.argmax(softmax)
    confidence = softmax[outlier_index]

    return outlier_index, confidence


def locs_based_analysis(ref_locs_movie, nuc_movie, pattern, max_dis=5, save=True):
    # the input is either path of tif files or hdf5 files
    if ref_locs_movie.endswith('.tif') and np.all([x.endswith('.tif') for x in nuc_movie]):
        nuc_locs, ref_locs = get_corrected_localizations(nuc_movie, ref_locs_movie, pattern, save)


    elif ref_locs_movie.endswith('.hdf5') and nuc_movie.endswith('.hdf5'):
        nuc_locs = pd.read_hdf(nuc_movie, 'locs')
        ref_locs = pd.read_hdf(ref_locs_movie, 'locs')

    else:
        raise ValueError('The input files should be either tif or hdf5 files')

    detection_results = []
    for idx, row in ref_locs.iterrows():
        xc = row['x']
        yc = row['y']
        subset = nuc_locs[(nuc_locs.x - xc)**2 + (nuc_locs.y - yc)**2 < max_dis**2].copy()
        ns, counts = np.unique(subset['nuc'], return_counts=True)
        if len(ns) == 4 and np.all(counts > 2):
            param = subset.groupby('nuc', sort=True).mean()
            param['num'] = counts
            outlier, confidence = outlier_detection(param)
        else:
            outlier, confidence = 4, 0

        detection_results.append([xc, yc, outlier, confidence])

    detection_results = pd.DataFrame(detection_results, columns=['x', 'y', 'outlier', 'confidence'])
    detection_results['outlier'] = detection_results['outlier'].replace(
        {0: 'A', 1: 'C', 2: 'G', 3: 'T', 4: 'No signal'})

    save_path = os.path.dirname(ref_locs_movie) + '/detection_results.csv'
    detection_results.to_csv(save_path, index=False)

    print(detection_results.value_counts(subset=['outlier']))

    return detection_results


if __name__ == '__main__':
    nuc_movs = ["H:\jagadish_data\locs_based_analysis\GAP_A_8nt_comp_df10_GAP_A_degen100nM_S3A300nM.tif",
                "H:\jagadish_data\locs_based_analysis\GAP_A_8nt_comp_df10_GAP_A_degen100nM_S3C300nM.tif",
                "H:\jagadish_data\locs_based_analysis\GAP_A_8nt_comp_df10_GAP_A_degen100nM_S3G300nM.tif",
                "H:\jagadish_data\locs_based_analysis\GAP_A_8nt_comp_df10_GAP_A_degen100nM_S3T300nM-2.tif"]
    locs_based_analysis("H:\jagadish_data\locs_based_analysis\GAP_A_8nt_comp_df10_GAP_A_Localization.tif",
                        nuc_movie=nuc_movs, pattern='_S3(.+?)300nM')