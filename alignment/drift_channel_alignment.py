import cupy as cp
from cupyx.scipy.ndimage import shift as cupy_shift
import numpy as np
from picasso.gausslq import locs_from_fits_gpufit, initial_parameters_gpufit
from pygpufit import gpufit as gf
from picasso.io import load_movie
from picasso.localize import identify_async, identifications_from_futures, get_spots
from picasso.aim import aim
from picasso.imageprocess import rcc
import picasso.render as _render
from tifffile import imwrite, imread
import multiprocessing
from pystackreg import StackReg
from scipy.ndimage import affine_transform, shift, gaussian_filter1d


class movie_class():
    def __init__(self, movie_path, roi=None):
        self.movie_path = movie_path
        self.roi = roi

        self.movie = None
        self.locs = None
        self.info = None
        #self.drift_corrected = None

    def __getitem__(self, index):
        return self.movie[index]

    # this function is modified from the localize function in picasso.localize
    # and it exports the fitting quality as well
    def fit_spots_gpufit(self, spots):
        size = spots.shape[1]
        initial_parameters = initial_parameters_gpufit(spots, size)
        spots.shape = (len(spots), (size * size))
        model_id = gf.ModelID.GAUSS_2D_ELLIPTIC

        parameters, states, chi_squares, number_iterations, exec_time = gf.fit(
            spots,
            None,
            model_id,
            initial_parameters,
            tolerance=1e-2,
            max_number_iterations=20,
        )

        parameters[:, 0] *= 2.0 * np.pi * parameters[:, 3] * parameters[:, 4]

        return parameters

    # this function selects  and modifies a part of codes frm picasso.main
    def lq_gpu_fitting(self, min_net_gradient=400, box=5):
        camera_info = {}
        camera_info["Baseline"] = 400
        camera_info["Sensitivity"] = 2.5
        camera_info["Gain"] = 1
        camera_info["qe"] = 0.82

        movie, info = load_movie(self.movie_path)
        # handle the roi before feeding it into the picasso functions
        if self.roi is not None:
            movie = movie[:, self.roi[0]: self.roi[2], self.roi[1]: self.roi[3]]
            self.movie = movie

            info[0]['Width'] = self.roi[3] - self.roi[1]
            info[0]['Height'] = self.roi[2] - self.roi[0]

        current, futures = identify_async(movie, min_net_gradient, box, roi=None)
        ids = identifications_from_futures(futures)

        spots = get_spots(movie, ids, box, camera_info)
        theta = self.fit_spots_gpufit(spots)
        em = camera_info["Gain"] > 1
        locs = locs_from_fits_gpufit(ids, theta, box, em)

        localize_info = {
            "Generated by": "Picasso Localize",
            "ROI": None,
            "Box Size": box,
            "Min. Net Gradient": min_net_gradient,
            "Convergence Criterion": 0,
            "Max. Iterations": 0,
            "Pixelsize": 117,
            "Fit method": 'lq-gpu'}

        info.append(localize_info)
        self.locs = locs
        self.info = info

        return


    def drift_correction(self):
        #self.lq_gpu_fitting(min_net_gradient=min_net_gradient, box=box)
        # the movie will be set during the lq_gpu_fitting
        if self.locs is None:
            raise ValueError("Please identify locs form the movie first")

        corrected_locs, new_info, drift = aim(self.locs, self.info, segmentation=100, intersect_d=20 / 117, roi_r=60 / 117)
        drift = drift.view(np.recarray)

        # apply negative drift frame by frame using GPU
        movie_gpu = cp.asarray(self.movie)
        corrected_movie_gpu = cp.empty_like(movie_gpu)
        for i in range(movie_gpu.shape[0]):
            aim_shift = (-drift[i][1], -drift[i][0])
            corrected_movie_gpu[i] = cupy_shift(movie_gpu[i], aim_shift, mode='constant', cval=0, order=0)

        corrected_movie = cp.asnumpy(corrected_movie_gpu)
        self.movie = corrected_movie
        self.locs = corrected_locs
        self.info = new_info

        return



def gaussian_bg_remove(movie, sigma_spatial=20):
    bg = gaussian_filter1d(movie, sigma=sigma_spatial, axis=1)
    bg = gaussian_filter1d(bg, sigma=sigma_spatial, axis=2)
    bg = np.where(movie > bg, bg, movie)

    bg_removed = movie - bg

    return bg_removed


def transform_frame(idx, frame, transform_mat):
    # sr = StackReg(StackReg.RIGID_BODY)
    # return idx, sr.transform(frame, tmat=transform_mat)
    return idx, affine_transform(frame, transform_mat, order=0)

def stackreg_channel_alignment(ref, mov):
    sr = StackReg(StackReg.RIGID_BODY)

    avg_mov = mov.mean(axis=0)
    transform_mat = sr.register(ref, avg_mov)

    args = [(j, mov[j, :, :], transform_mat) for j in range(mov.shape[0])]
    aligned_mov = np.zeros_like(mov)
    with multiprocessing.Pool() as pool:
        for i, aligned_frame in pool.starmap(transform_frame, args):
            aligned_mov[i, :, :] = aligned_frame

    channel_corrected = aligned_mov

    return channel_corrected


def position_correction(movie_path_list, ref_movie_path, roi=None,  ref_roi=None,
                        save=True, channel_align_method='RCC'):

    ''' This function contains two steps: 1.acquire localizations from the movie and using aim to calculate the
        drift then apply it to the movie for drift correction 2. acquire the transformation using the average image from the
        movies then apply the same matrix for all frames in movies for channel alignment '''

    if channel_align_method == 'RCC':
        ref = movie_class(ref_movie_path, ref_roi)
        ref.lq_gpu_fitting()

        if save:
            imwrite(ref_movie_path.replace('.tif', '_chopped.tif'), ref.movie)

        for movie_path in movie_path_list:
            mov = movie_class(movie_path, roi)
            mov.lq_gpu_fitting()
            mov.drift_correction()

            _, ref_image = _render.render(ref.locs, ref.info)
            _, mov_image = _render.render(mov.locs, mov.info)
            shift_y, shift_x = rcc([ref_image, mov_image])
            aligned_movie = shift(mov.movie, (0, -shift_y[1], -shift_x[1]), mode='constant', cval=0, order=0)

            bg_removed = gaussian_bg_remove(aligned_movie)

            if save:
                imwrite(movie_path.replace('.tif', '_corrected.tif'), bg_removed)


    elif channel_align_method == 'StackReg':
        ref = imread(ref_movie_path)
        if ref_roi is not None:
            if len(ref.shape) == 2:
                ref = ref[ref_roi[0]: ref_roi[2], ref_roi[1]: ref_roi[3]]
            elif len(ref.shape) == 3:
                ref = ref[:, ref_roi[0]: ref_roi[2], ref_roi[1]: ref_roi[3]]
            else:
                raise ValueError('The reference image has the wrong shape')

            if save:
                imwrite(ref_movie_path.replace('.tif', '_chopped.tif'), ref)

        for movie_path in movie_path_list:
            mov = movie_class(movie_path, roi)
            mov.lq_gpu_fitting()
            mov.drift_correction()

            ref = ref.mean(axis=0)
            aligned_movie = stackreg_channel_alignment(ref, mov.movie)
            bg_removed = gaussian_bg_remove(aligned_movie)

            if save:
                imwrite(movie_path.replace('.tif', '_corrected.tif'), bg_removed)

    else:
        raise ValueError('The channel alignment method is not supported')


    return




if __name__ == "__main__":
    ref = "H:/jagadish_data/20240518_3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM/3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM_localizaiton.tif"
    ref_roi = [0, 0, 684, 420]  # green channel # Note that two NIM have different width

    mov_list = ["H:/jagadish_data/20240518_3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM/3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM_seal5A_1uM_degen0.5uM.tif",
           "H:/jagadish_data/20240518_3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM/3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM_seal5C_1uM_degen0.5uM.tif",
           "H:/jagadish_data/20240518_3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM/3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM_seal5G_1uM_degen0.5uM.tif",
           "H:/jagadish_data/20240518_3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM/3ntSeq_pos5_dex15form15_degen0.5uMcomp1uM_seal5T_1uM_degen0.5uM.tif"]
    roi = [0, 420, 684, 840]  # red channel

    position_correction(mov_list, ref, roi=roi, ref_roi=ref_roi, save=True, channel_align_method='RCC')






