from scipy.ndimage import shift as scipy_shift
import os
import numpy as np
from picasso.gausslq import locs_from_fits_gpufit, initial_parameters_gpufit
from pygpufit import gpufit as gf
from picasso.io import load_movie
from picasso.localize import identify_async, identifications_from_futures, get_spots
from picasso.aim import aim
from tifffile import imwrite, imread
from multiprocessing import Pool
from pystackreg import StackReg
from scipy.ndimage import affine_transform
import re

# this function is modified from the localize function in picasso.localize
# and it exports the fitting quality as well
def fit_spots_gpufit(spots):
    size = spots.shape[1]
    initial_parameters = initial_parameters_gpufit(spots, size)
    spots.shape = (len(spots), (size * size))
    model_id = gf.ModelID.GAUSS_2D_ELLIPTIC

    parameters, states, chi_squares, number_iterations, exec_time = gf.fit(
        spots,
        None,
        model_id,
        initial_parameters,
        tolerance=1e-2,
        max_number_iterations=20,
    )

    parameters[:, 0] *= 2.0 * np.pi * parameters[:, 3] * parameters[:, 4]

    return parameters


# this function selects  and modifies a part of codes frm picasso.main
def lq_gpu_fitting(path, width):
    _, ext = os.path.splitext(path)

    camera_info = {}
    camera_info["Baseline"] = 400
    camera_info["Sensitivity"] = 2.5
    camera_info["Gain"] = 1
    camera_info["qe"] = 0.82

    min_net_gradient = 400
    box = 5
    roi = None

    movie, info = load_movie(path)
    movie = movie[:, :, width:]
    info[0]['Width'] = width

    current, futures = identify_async(movie, min_net_gradient, box, roi=roi)
    ids = identifications_from_futures(futures)

    spots = get_spots(movie, ids, box, camera_info)
    theta = fit_spots_gpufit(spots)
    em = camera_info["Gain"] > 1
    locs = locs_from_fits_gpufit(ids, theta, box, em)

    localize_info = {
        "Generated by": "Picasso Localize",
        "ROI": roi,
        "Box Size": box,
        "Min. Net Gradient": min_net_gradient,
        "Convergence Criterion": 0,
        "Max. Iterations": 0,
        "Pixelsize": 117,
        "Fit method": 'lq-gpu'}

    info.append(localize_info)

    return locs, info

def correct_frame(idx, frame, drift):
    aim_shift = (-drift[1], -drift[0])
    return idx, scipy_shift(frame, aim_shift, mode='constant', cval=0, order=0)

def drift_correction(movie_path):
    movie = imread(movie_path)
    width = movie.shape[2] // 2  # in the x direction
    movie = movie[:, :, width:]

    locs, info = lq_gpu_fitting(movie_path, width)
    locs, new_info, drift = aim(locs, info, segmentation=100, intersect_d=20 / 117, roi_r=60 / 117)

    drift = drift.view(np.recarray)

    #corrected_movie = np.array(Parallel(n_jobs=-1)(delayed(correct_frame)(i) for i in range(movie.shape[0])))

    args = [(i, movie[i, :, :], drift[i]) for i in range(movie.shape[0])]
    corrected_movie = np.zeros_like(movie)
    corrected_movie[0, :, :] = movie[0, :, :]
    with Pool() as pool:
        for i, corrected_frame in pool.starmap(correct_frame, args):
            corrected_movie[i, :, :] = corrected_frame

    return corrected_movie

def transform_frame(idx, frame, transform_mat):
    # sr = StackReg(StackReg.RIGID_BODY)
    # return idx, sr.transform(frame, tmat=transform_mat)
    return idx, affine_transform(frame, transform_mat, order=0)


def channel_alignment(ref, mov):
    sr = StackReg(StackReg.RIGID_BODY)

    avg_mov = mov.mean(axis=0)
    transform_mat = sr.register(ref, avg_mov)
    # transform_matrix_stack = np.tile(transform_mat, (mov.shape[0], 1, 1))
    # aligned_mov = sr.transform_stack(mov, tmats=transform_matrix_stack)

    args = [(j, mov[j, :, :], transform_mat) for j in range(mov.shape[0])]
    aligned_mov = np.zeros_like(mov)
    with Pool() as pool:
        for i, aligned_frame in pool.starmap(transform_frame, args):
            aligned_mov[i, :, :] = aligned_frame

    return aligned_mov

# def channel_alignment(ref, mov):
#     sr = StackReg(StackReg.RIGID_BODY)
#     transform_mat = sr.register(ref, mov)
#     aligned_mov = affine_transform(mov, transform_mat, order=0)
#
#     return aligned_mov


def position_correction(dir_path, ref_localization_path, save=False):
    ''' This function contains two steps: 1.acquire localizations from the movie and using aim to calculate the
    drift then apply it to the movie for drift correction 2. acquire the transformation using the average image from the
    movies then apply the same matrix for all frames in movies for channel alignment '''

    files = os.listdir(dir_path)
    movie_paths = [x for x in files if x.endswith('.tif')]

    drift_free = {}
    for m in movie_paths:
        drift_free[m] = drift_correction(dir_path + '/' + m)

    #ref = drift_free[0].mean(axis=0)
    #imwrite(dir_path + '/' + movie_paths[0].replace('.tif', '_corrected.tif'), drift_free[0])
    ref = imread(ref_localization_path)
    ref = ref.mean(axis=0)


    pos_corrected = {}
    for m in movie_paths:
        aligned_movie = channel_alignment(ref, drift_free[m].sum())
        pos_corrected[m] = aligned_movie
        if save:
            imwrite(dir_path + '/' + m.replace('.tif', '_corrected.tif'), aligned_movie)

    return pos_corrected




if __name__ == "__main__":
    dir_path = ("H:/jagadish_data/channelAlignment_driftCorrection/20250128_7ntGAP_T_Non-comp_degen100nMdex10%form10/movies")
    position_correction(dir_path)





