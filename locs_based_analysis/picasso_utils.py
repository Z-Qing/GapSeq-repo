from picasso.gausslq import locs_from_fits_gpufit, fit_spots_gpufit, fit_spots_parallel, locs_from_fits
from picasso.io import load_movie
from picasso.localize import identify_async, identifications_from_futures, get_spots
from picasso.aim import aim
from picasso.clusterer import dbscan
from picasso.postprocess import link
import cupy as cp
from cupyx.scipy.ndimage import shift as cupy_shift
from cupyx.scipy.ndimage import median_filter, gaussian_filter
from scipy.spatial import KDTree
from scipy.ndimage import shift
import numpy as np
from numpy.lib import recfunctions as rfn



class one_channel_movie(object):
    def __init__(self, movie_path, roi=None, frame_range=None):
        self.movie_path = movie_path
        self.roi = roi
        self.frame_range = frame_range
        self.camera_info = {}

        self.movie = None
        self.locs = None
        self.info = None

    def __getitem__(self, index):
        return self.movie[index]

    # this function is modified from the localize function in picasso.localize
    # and it exports the fitting quality as well
    def io_movie_format(self):
        movie, info = load_movie(self.movie_path)

        self.camera_info["Baseline"] = 400
        self.camera_info["Sensitivity"] = 2.5
        self.camera_info["Gain"] = 1
        self.camera_info["qe"] = 0.82

        # handle the roi before feeding it into the picasso functions
        if self.roi is not None:
            movie = movie[:, self.roi[0]: self.roi[2], self.roi[1]: self.roi[3]]

            info[0]['Width'] = self.roi[3] - self.roi[1]
            info[0]['Height'] = self.roi[2] - self.roi[0]

        # change the frame range if it is not None
        if self.frame_range is not None:
            if isinstance(self.frame_range, (list, tuple)):
                movie = movie[self.frame_range[0]: self.frame_range[1], :, :]
                info[0]['Frames'] = self.frame_range[1] - self.frame_range[0]

            if isinstance(self.frame_range, int):
                movie = movie[self.frame_range, :, :]
                movie = movie[np.newaxis, :, :]
                info[0]['Frames'] = 1

            else:
                raise ValueError("frame_range must be a list/tuple for a range or"
                                 " an integer for a single frame")

        self.movie = movie
        self.info = info

        return



    # this function selects  and modifies a part of codes frm picasso.main
    def lq_gpu_fitting(self, min_net_gradient=400, box=5):
        camera_info = self.camera_info

        current, futures = identify_async(self.movie, min_net_gradient, box, roi=None)
        ids = identifications_from_futures(futures)

        spots = get_spots(self.movie, ids, box, camera_info)
        theta = fit_spots_gpufit(spots)
        em = camera_info["Gain"] > 1
        locs = locs_from_fits_gpufit(ids, theta, box, em)

        localize_info = {
            "Generated by": "Picasso Localize",
            "ROI": None,
            "Box Size": box,
            "Min. Net Gradient": min_net_gradient,
            "Convergence Criterion": 0,
            "Max. Iterations": 0,
            "Pixelsize": 117,
            "Fit method": 'lq-gpu'}

        self.info.append(localize_info)
        self.locs = locs

        return

    def lq_cpu_fitting(self, min_net_gradient=400, box=5):
        camera_info = self.camera_info

        current, futures = identify_async(self.movie, min_net_gradient, box, roi=None)
        ids = identifications_from_futures(futures)

        spots = get_spots(self.movie, ids, box, camera_info)
        theta = fit_spots_parallel(spots)
        locs = locs_from_fits(ids, theta, box, camera_info["Gain"])

        localize_info = {
            "Generated by": "Picasso Localize",
            "ROI": None,
            "Box Size": box,
            "Min. Net Gradient": min_net_gradient,
            "Convergence Criterion": 0,
            "Max. Iterations": 0,
            "Pixelsize": 117,
            "Fit method": 'lq'}

        self.info.append(localize_info)
        self.locs = locs

        return

    def lq_fitting(self, GPU, min_net_gradient=400, box=5):
        if self.movie == None or self.info ==None:
            self.io_movie_format()

        if GPU:
            self.lq_gpu_fitting(min_net_gradient, box)
        else:
            self.lq_cpu_fitting(min_net_gradient, box)


    def drift_correction(self, GPU=True, segmentation=100, intersect_d=20 / 117, roi_r=60 / 117):
        # self.lq_gpu_fitting(min_net_gradient=min_net_gradient, box=box)
        # the movie will be set during the lq_gpu_fitting
        if self.locs is None:
            raise ValueError("Please identify locs form the movie first")

        if max(self.locs['frame']) >= 3 * segmentation:
            corrected_locs, new_info, drift = aim(self.locs, self.info,
                                                  segmentation=segmentation, intersect_d=intersect_d, roi_r=roi_r)
            drift = drift.view(np.recarray)

            if GPU:
                # apply negative drift frame by frame using GPU
                movie_gpu = cp.asarray(self.movie)
                corrected_movie_gpu = cp.empty_like(movie_gpu)
                for i in range(movie_gpu.shape[0]):
                    aim_shift = (-drift[i][1], -drift[i][0])
                    corrected_movie_gpu[i] = cupy_shift(movie_gpu[i], aim_shift, mode='constant', cval=0, order=0)

                corrected_movie = cp.asnumpy(corrected_movie_gpu)

            else:
                corrected_movie = np.empty_like(self.movie)
                for i in range(self.movie.shape[0]):
                    aim_shift = (-drift[i][1], -drift[i][0])
                    corrected_movie[i] = shift(self.movie[i], aim_shift, mode='constant', cval=0, order=0)

            self.movie = corrected_movie
            self.locs = corrected_locs
            self.info = new_info

        else:
            pass

        return

    def dbscan(self, eps=0.5, min_samples=20):
        if self.locs is None:
            raise ValueError('Please run localization function first')

        clusters = dbscan(self.locs, radius=eps, min_samples=min_samples)

        self.locs = clusters

        return

    def link(self, r_max=1, max_dark_time=1):
        if self.locs is None:
            raise ValueError('Please run localization function first')

        linked_locs = link(self.locs, self.info, r_max=r_max, max_dark_time=max_dark_time)

        self.locs = linked_locs

        return


    def median_filter(self, radius=20):
        image_stack = cp.asarray(self.movie)
        bg = median_filter(image_stack, size=(1, radius, radius))
        filtered_stack = image_stack - bg
        filtered_stack = np.where(filtered_stack > 0, filtered_stack, 0)

        self.movie = cp.asnumpy(filtered_stack)
        self.camera_info['Baseline'] = 10

        return


    def gaussian_filter(self, sigam=10):
        image_stack = cp.asarray(self.movie)
        bg = gaussian_filter(image_stack, sigma=(1, sigam, sigam))
        filtered_stack = image_stack - bg
        filtered_stack = np.where(filtered_stack > 0, filtered_stack, 0)

        self.movie = cp.asnumpy(filtered_stack)
        self.camera_info['Baseline'] = 10  # temp value

        return


    def find_no_neighbour_mask(self, locs, box_radius):
        points = np.column_stack((locs['x'], locs['y']))

        # Build KDTree for fast neighbor lookup
        tree = KDTree(points)

        # Find neighbors within the given radius
        indices = tree.query_ball_point(points, box_radius)

        # Keep only points with no close neighbors (excluding self)
        keep_mask = np.array([len(neigh) == 1 for neigh in indices])

        return keep_mask

    def overlap_prevent(self, box_radius=2):
        # ----------------- remove overlapping locs frame by frame -----------------

        unique_frames = np.unique(self.locs['frame'])  # Get all unique frame IDs
        filtered_locs = []  # Store results for all frames

        for frame in unique_frames:
            # Select points in the current frame
            mask = self.locs['frame'] == frame
            frame_locs = self.locs[mask]

            if len(frame_locs) == 0:
                continue  # Skip empty frames

            keep_mask = self.find_no_neighbour_mask(frame_locs, box_radius)
            filtered_locs.append(frame_locs[keep_mask])

        concatenated_locs = rfn.stack_arrays(filtered_locs, asrecarray=True)
        self.locs = concatenated_locs.view(np.recarray)

        return

