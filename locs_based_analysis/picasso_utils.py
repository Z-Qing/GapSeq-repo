import pandas as pd
from picasso.gausslq import locs_from_fits_gpufit, fit_spots_parallel, locs_from_fits, fits_from_futures
from picasso.io import load_movie
from picasso.localize import identify_async, identifications_from_futures, get_spots
from picasso.aim import aim
from picasso.clusterer import dbscan
from picasso.postprocess import link
from picasso.lib import ensure_sanity, n_futures_done
from scipy.spatial import KDTree
from scipy.ndimage import uniform_filter, shift
import numpy as np
from numpy.lib import recfunctions as rfn
import matplotlib.pyplot as plt
import time

try:
    import cupy as cp
    from cupyx.scipy.ndimage import shift as cupy_shift
    from picasso.gausslq import fit_spots_gpufit
except:
    pass



class one_channel_movie(object):
    def __init__(self, mov, roi=None, frame_range=np.inf):
        if isinstance(mov, str):
            self.movie_path = mov
            self.movie = None
            self.info = None

        elif isinstance(mov, np.ndarray):
            self.movie = mov
            self.movie_path = None
            initial_dict = {'Byte Order': '<',
                            'Data Type': 'uint16',
                            'File': '',
                            'Frames': mov.shape[0],
                            'Height': mov.shape[1],
                            'Micro-Manager Acquisiton Comments': '',
                            'Width': mov.shape[2],}
            self.info = [initial_dict]
        else:
            raise ValueError("movie must be a string (path to the movie file) or a numpy array")

        self.roi = roi
        self.frame_range = frame_range
        self.camera_info = {}

        self.locs = None
        #self.cluster_param = None

    def __getitem__(self, index):
        return self.movie[index]

    # this function is modified from the localize function in picasso.localize
    # and it exports the fitting quality as well
    def movie_format(self, baseline=400):
        # print(self.movie_path)
        # print(self.movie)
        if self.movie_path is not None and self.movie is None:
            movie, info = load_movie(self.movie_path)
            # handle the roi before feeding it into the picasso functions
            if self.roi is not None:
                movie = movie[:, self.roi[0]: self.roi[2], self.roi[1]: self.roi[3]]

                info[0]['Width'] = self.roi[3] - self.roi[1]
                info[0]['Height'] = self.roi[2] - self.roi[0]


            # change the frame range if it is not None
            if self.frame_range is not np.inf:
                if isinstance(self.frame_range, (list, tuple)):
                    if self.frame_range[1] is np.inf:
                        movie = movie[self.frame_range[0]:, :, :]
                    else:
                        movie = movie[self.frame_range[0]: self.frame_range[1], :, :]
                        info[0]['Frames'] = self.frame_range[1] - self.frame_range[0]

                elif isinstance(self.frame_range, int):
                    movie = movie[self.frame_range, :, :]
                    movie = movie[np.newaxis, :, :]
                    info[0]['Frames'] = 1


                else:
                    raise ValueError("frame_range must be a list/tuple for a range or"
                                     " an integer for a single frame")

        elif self.movie is not None and self.movie_path is None:
            movie = self.movie
            info = self.info
        else:
            raise ValueError("Please provide either a movie path or a movie array")

        self.camera_info["Baseline"] = baseline
        self.camera_info["Sensitivity"] = 2.5
        self.camera_info["Gain"] = 1
        self.camera_info["qe"] = 0.82

        self.movie = movie
        self.info = info

        return


    def lq_fitting(self, GPU, gradient=400, box=5):
        if self.movie is None or self.info is None:
            self.movie_format()

        curr, futures = identify_async(self.movie, gradient, box, roi=None)
        N = len(self.movie)
        while curr[0] < N:
            time.sleep(0.2)
        ids = identifications_from_futures(futures)
        spots = get_spots(self.movie, ids, box, self.camera_info)
        em = self.camera_info["Gain"] > 1

        if GPU:
            theta = fit_spots_gpufit(spots)
            locs = locs_from_fits_gpufit(ids, theta, box, em)
        else:
            fs = fit_spots_parallel(spots, asynch=True)
            n_tasks = len(fs)
            while n_futures_done(fs) < n_tasks:
                time.sleep(0.2)
            theta = fits_from_futures(fs)
            locs = locs_from_fits(ids, theta, box, em)

        localize_info = {
            "Generated by": "Picasso Localize",
            "ROI": None,
            "Box Size": box,
            "Min. Net Gradient": gradient,
            "Convergence Criterion": 0,
            "Max. Iterations": 0,
            "Pixelsize": 117,
            "Fit method": 'lq'}

        self.info.append(localize_info)
        self.locs = ensure_sanity(locs, self.info)

        return


    def drift_correction(self, GPU=True, drift=None, segmentation=100,
                         intersect_d=20 / 117, roi_r=60 / 117):
        # self.lq_gpu_fitting(min_net_gradient=min_net_gradient, box=box)
        # the movie will be set during the lq_gpu_fitting
        if drift is None and max(self.locs.frame) >= 3 * segmentation:
            corrected_locs, new_info, drift = aim(self.locs, self.info,
                        segmentation=segmentation, intersect_d=intersect_d, roi_r=roi_r)

            drift = drift.view(np.recarray)
            self.locs = corrected_locs
            self.info = new_info
            # else:
            #     drift = np.zeros((len(self.locs), 2))

        if drift is not None:
            if GPU:
                # apply negative drift frame by frame using GPU
                movie_gpu = cp.asarray(self.movie)
                # print(movie_gpu.shape[0])
                corrected_movie_gpu = cp.empty_like(movie_gpu)
                for i in np.arange(movie_gpu.shape[0]):
                    aim_shift = (-drift[i][1], -drift[i][0])
                    corrected_movie_gpu[i] = cupy_shift(movie_gpu[i], aim_shift, mode='constant', cval=0, order=1)

                corrected_movie = cp.asnumpy(corrected_movie_gpu)

            else:
                corrected_movie = np.empty_like(self.movie)
                for i in range(self.movie.shape[0]):
                    aim_shift = (-drift[i][1], -drift[i][0])
                    corrected_movie[i] = shift(self.movie[i], aim_shift, mode='constant', cval=0, order=1)

            self.movie = corrected_movie

        return drift



    def dbscan(self, eps=0.5, min_samples=20):
        if self.locs is None:
            raise ValueError('Please run localization function first')

        clusters = dbscan(self.locs, radius=eps, min_samples=min_samples)

        self.locs = clusters

        self.cluster_param = pd.DataFrame(self.locs).groupby('group').mean()[['x', 'y']]
        self.cluster_param['count'] = pd.DataFrame(self.locs).groupby('group').size()

        return


    def link(self, r_max=1, max_dark_time=1):
        if self.locs is None:
            raise ValueError('Please run localization function first')

        linked_locs = link(self.locs, self.info, r_max=r_max, max_dark_time=max_dark_time)

        self.locs = linked_locs


        return


    def find_no_neighbour_mask(self, locs, box_radius):
        points = np.column_stack((locs['x'], locs['y']))

        # Build KDTree for fast neighbor lookup
        tree = KDTree(points)

        # Find neighbors within the given radius
        indices = tree.query_ball_point(points, box_radius)

        # Keep only points with no close neighbors (excluding self)
        keep_mask = np.array([len(neigh) == 1 for neigh in indices])

        return keep_mask


    def overlap_prevent(self, box_radius=2):
        # ----------------- remove overlapping locs frame by frame -----------------

        unique_frames = np.unique(self.locs['frame'])  # Get all unique frame IDs
        filtered_locs = []  # Store results for all frames

        for frame in unique_frames:
            # Select points in the current frame
            mask = self.locs['frame'] == frame
            frame_locs = self.locs[mask]

            if len(frame_locs) == 0:
                continue  # Skip empty frames

            keep_mask = self.find_no_neighbour_mask(frame_locs, box_radius)
            filtered_locs.append(frame_locs[keep_mask])

        concatenated_locs = rfn.stack_arrays(filtered_locs, asrecarray=True)
        self.locs = concatenated_locs.view(np.recarray)

        return
